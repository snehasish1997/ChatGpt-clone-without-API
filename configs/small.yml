seq_len: 512
vocab_size: 8000
n_layers: 8
n_heads: 8
d_model: 512
d_ff: 2048
dropout: 0.1
batch_size: 16
lr: 2.0e-4
min_lr: 1.0e-5
warmup_steps: 1000
max_steps: 20000
weight_decay: 0.01
grad_accum_steps: 4
compile: true
